---
title: "TropFishR tutorial: Fish stock assessment with length-frequency data"
author: "Tobias K. Mildenberger"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
      fig_caption: yes
      number_sections: yes
vignette: >
  %\VignetteIndexEntry{tutorial}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
csl: mee.csl
bibliography: TropFishR.bib
---

```{r ReaddataLoadLibraries, message=FALSE, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      cache = FALSE, 
                      warning = FALSE, 
                      eval = FALSE,
                      error = FALSE,
                      warning = FALSE,
                      message = FALSE,
                      include = TRUE,
                      collapse = TRUE,
                      comment = "#>",
                      fig.show = "hold",
                      fig.width=8, fig.height=7)
```


#*Introduction*
This tutorial illustrates the application of functions in the **`TropFishR`**  package to perform a fish stock assessment with length frequency data: (i) estimation of biological stock characteristics (growth and natural mortality), (ii) fisheries aspects (exploitation rate and selectivity), (iii) stock size and status. The order of the methods is important as they build upon each other in a sequential way. In a real situation, literature data can be used to skip a step in this workflow or even better to compare literature values with the outcomes of this routine. 
Here, I apply these steps to generated length-frequency (LFQ) data with known parameters, which allows to evaluate methods by comparing results to the true parameters. 
The package is relatively easy to use for those inexperienced in R, however complete access and control is available to more experienced users.
TropFishR has been used in derving manamgent advice for the artisanal fisheries in Kenya and is being used to asses the fish stocks at the Pacfic coast of Colombia.

##*Installing TropFishR*
The current version of **`TropFishR`** (v1.0.2) requires R $>= 3.0.0$ and can be downloaded from CRAN as follows:
```{r, echo = TRUE, include = TRUE, eval = FALSE}
install.packages("TropFishR")
```
The development version (v1.0.3) can be downloaded from Github.
```{r, echo = TRUE, include = TRUE, eval = FALSE}
install.packages("devtools")
devtools::install_github("tokami/TropFishR")
```

Then the package is loaded into the R environment:
```{r, eval=TRUE,echo=TRUE}
library(TropFishR)
```


#*Tropical fish stock assessment using TropFishR*
The tutorial will make use of two LFQ data sets included in the package called "synLFQ4" and "synLFQ6".

##*Biological stock characteristics*
Growth, natural mortality, recruitment patterns and stock-recruitment relationship are important biological stock characteristics and input parameters for population dynamics models.

###*Growth parameters*
In most cases, growth parameters refers to the asymptotic length ($L_{inf}$), the growth coefficient (K) and the theoretical length at age zero ($t_{0}$) of the von Bertalanffy growth function (VBGF). The ELEFAN (ELectronic LEngth Frequency ANalysis) pacakge allows to $L_{inf}$ and K from LFQ data by resturcturing the data and fitting growth curves through the restructured LFQ data [@Pauly1980]. 
I recommend to start by visualisation of the raw and restructured LFQ data, which aids in determining appropriate bin sizes and moving average of the restructuring procedure. The argument 'addl.sqrt' allows to apply an additional squareroot transformation in the restructuring process, which controls the impact of large individuals.

```{r Figure 1, echo=TRUE, eval=TRUE, fig.cap="Length frequency data visualised in terms of (a) catches and (b) restructured data with MA = 7."}
# set seed value for reproducible results
set.seed(10) 
# plot raw and restructured LFQ data
lfqbin <- lfqRestructure(synLFQ6, MA = 7, addl.sqrt = TRUE)
par(mfrow = c(2,1), mar = c(2,5,2,3), oma = c(2,0,0,0))
plot(lfqbin, Fname = "catch", date.axis = "modern")
plot(lfqbin, Fname = "rcounts", date.axis = "modern")
```

For synLFQ6, a bin size of 2 and a moving average of 7 seems appropriate and will be used in the following. To get a first estimate of $L_{inf}$, the powell-wetherall method [@Wetherall1987] can be applied. The method requires a catch vetor per length class representative for length distribution in yearly catches instead of a catch matrix, the argument `catch_columns` allows to choose the columns of the catch matrix which will be summarised for the analysis. Here all columns are used as the catch matrix only includes catches from 2015.

```{r Figure 2, fig.width=6, fig.height=5, echo=TRUE, eval=TRUE, fig.cap="Powell-Wetherall plot to derive an estimate of Linf."}
# Powell Wetherall plot
res_PW <- powell_wetherall(param = synLFQ6, 
                           catch_columns = 1:ncol(synLFQ6$catch), 
                           reg_int = c(14,24))
```

The argument `reg_int` is necessary in this tutorial because this function includes an interactive plotting function where points for the regression analysis have to be selected by the user^[Typically, one would choose which points to include in the regression analysis by clicking on the interactive plot (for more information see `help(powell_wetherall)`).].

For the data of this exercise the Powell-Wetherall plot returns an $L_{inf}$ (± standard error) of 35.11 ± 0.86 cm, as determined by the x-intercept. This estimate can be used for further analysis with methods of the package ELEFAN. In **`TropFishR`**, there are 4 different methods based on ELEFAN: (i) K-Scan for the estimation of K for a fixed value of $L_{inf}$, (ii) Response Surface Analysis (RSA), (iii) ELEFAN with simulated annealing ('ELEFAN_SA'), and (iv) ELEFAN with genetic algorithm ('ELEFAN_GA'), which all allow to estimate K and $L_{inf}$ simultaneously. 

To get a quick K value corresponding to the $L_{inf}$ estimate of the Powell Wetherall method, the estimate can be assigned to the argument `Linf_fix` in the function 'ELEFAN':

```{r, include=TRUE, fig.width=6, fig.height=6, eval = TRUE, echo=TRUE, fig.cap="Example of a K-Scan application for the estimation of K to a corresponding Linf value. Graph shows the score function for different K values."}
res_KScan <- ELEFAN(synLFQ6, Linf_fix = res_PW$Linf_est, 
                    MA=7, addl.sqrt=TRUE, hide.progressbar = TRUE)
```

This method, however, does not allow to test if different combinations of $L_{inf}$ and K might result in a better fit. RSA with a range around the $L_{inf}$ estimate from the Powell-Wetherall method can be used to check different combinations. Alternatively, the maximum length in the data or the maxmimum length class^[or average of the several largest lengths or length classes] might be used as an reference for the search space of $L_{inf}$ [@Taylor1958; @Beverton1963]. For the Thumbprint Emperor data we chose a conservative range of potential $L_{inf}$ values of 29 cm to 55 cm, which corresponds to $0.8$ to $1.5$ times the maximum length class as suggested by @Pauly2013. Any range can be chosen, while a larger search space increases computing time but gives a better overview of the score over a wide range of $L_{inf}$ and $K$ combinations. A K range from 0.01 to 2 is relatively wide and should generally be sufficient.

```{r Figure 3, fig.width=8, eval = TRUE,  fig.cap="Results of response surface analysis of the Thumbprint Emperor data. Red colours indicate higher scoring parameter combinations indicative of a better fit."}
# Response surface analysis
res_RSA <- ELEFAN(synLFQ6, Linf_range = seq(30,40,1), MA = 7,
                     addl.sqrt = TRUE, K_range = seq(0.1,1,0.1), 
                     hide.progressbar = TRUE, contour=5)
```

It is generally recommendable to not settle with the first estimate from RSA, as it might find many local optima with close score values, but returns only the estimates associated with the highest score value. I recommend analysing several local maxima of the score function with a finer resolution for both parameters and compare the calculated score values and fit graphically. For the Thumbprint Emperor data, this procedure returns the highest score value (0.719) for estimates in Table 2 - RSA. 


```{r, eval = FALSE, echo=TRUE, include=TRUE, fig.cap="Analysing three highest local maxima with finer resolution. ResSurAna4 produced highest score and best visual fit through restructured data and was therefore chosen as the best solution of the traditional ELEFAN method, growth parameter are displayed in Table 2, column ELEFAN."}
# find 3 highest score values
n <- length(res_RSA$score_mat)
best_scores <- sort(res_RSA$score_mat,partial=n-0:2)[n-0:2]
ind <- arrayInd(which(res_RSA$score_mat %in% best_scores),
                dim(res_RSA$score_mat))
Ks <- as.numeric(rownames(res_RSA$score_mat)[ind[,1]])
Linfs <- as.numeric(colnames(res_RSA$score_mat)[ind[,2]])

res_loop <- vector("list", 3)
for(i in 1:3){
  tmp <- ELEFAN(synLFQ6,
                Linf_range = seq(Linfs[i]-2, Linfs[i]+2, 0.2), 
                K_range = seq(Ks[i]-0.1, Ks[i]+0.1, 0.05),
                MA = 7,
                addl.sqrt = TRUE, 
                hide.progressbar = TRUE, 
                contour=5)
  res_loop[[i]] <- cbind(Rn_max=tmp$Rn_max, t(as.matrix(tmp$par)))
}
results <- do.call(rbind, res_loop)

#      Rn_max Linf K    t_anchor  C ts phiL    
# [1,] 0.675  29.8 0.6  0.2481319 0 0  2.726584
# [2,] 0.719  34.8 0.45 0.2242925 0 0  2.736371
# [3,] 0.719  34.8 0.45 0.2242925 0 0  2.736371
```

The newly implemented ELEFAN method 'ELEFAN_SA' uses a simulated annealing algorithm [@Xiang2013] to solve for parameters of the VBGF. This optimisation procedure gradually reduces the stochasticity of the search process decreases as a function of decreasing 'temperature' value, which describes the probability of accepting worse conditions. In reference to the results of the Powell-Wetherall plot we conducted a second, more refined search within the range of 35 ± 5 cm for $L_{inf}$:

```{r Figure 4,  fig.height=5, fig.width=5, eval=TRUE, fig.cap="Score graph of the ELEFAN method with simulated annealing. Green dots indicate the runnning minimum value of the cost function, while blue dots indicate the mean score of each iteration. The red line shows the decline of the 'temperature' value, which describes the probability of accepting worse solutions as the parameter space is explored."}
# run ELEFAN with simulated annealing
res_SA <- ELEFAN_SA(synLFQ6, SA_time = 60*4, SA_temp = 6e5,
                     MA = 7, addl.sqrt = TRUE,
                     init_par = list(Linf = 35, K = 0.5, t_anchor = 0.5),
                     low_par = list(Linf = 30, K = 0.1, t_anchor = 0),
                     up_par = list(Linf = 40, K = 1, t_anchor = 1))
```

Note that the method with this setting takes a calculation time of less than 4 min for finding a stable optimum of the objective function (Fig. 4, Table 2 - 'ELEFAN_SA'), which is still substantially faster than the initial RSA search (around 8/5 min.). Computing time should be improved in the future by e.g. optimising the fitting process of growth curves.


```{r Figure 5, fig.height=5, fig.width=5, eval=TRUE, fig.cap="Score graph of the ELEFAN method with simulated annealing. Green dots indicate the runnning minimum value of the cost function, while blue dots indicate the mean score of each iteration. The red line shows the decline of the 'temperature' value, which describes the probability of accepting worse solutions as the parameter space is explored."}
# run ELEFAN with genetic algorithm
res_GA <- ELEFAN_GA(synLFQ6,maxiter = 100,
                     MA = 7, addl.sqrt = TRUE,
                     low_par = list(Linf = 30, K = 0.1, t_anchor = 0),
                     up_par = list(Linf = 40, K = 1, t_anchor = 1))
```


According to [@Pauly1980] it is not possible to estimate $t_{0}$ (theoretical age at length zero) from LFQ data alone. However, this parameter does not influence results of the methods of the traditional stock assessment workflow (catch curve, VPA/CA, and yield per recruit model) and can be set to zero (Mildenberger, unpublished). The ELEFAN methods in this package do not return starting points as FiSAT II users might be used to. Instead, they return the parameter 't_anchor', which describes the fraction of the year where yearly repeating growth curves cross length equal to zero; for example a value of 0.25 (or 3/12) refers to April 1st of any year. One of the benefits of the modern 'ELEFAN_SA' method is the possibility to estimate all parameters of the seasonalised VBGF simultaneously (by setting the argument `seasonalised == TRUE`). Until now, this was only possible to a limited extent within the 'Automatic Search' tab of FiSAT II, and required "understanding of how to conduct searches in multidimensional space, in the presence of multiple local optima" [@Gayanilo1997a]. The fit of resulting growth parameters of the seasonalised VBGF are promising [@Taylor2016]. The maximum age is also estimated within the ELEFAN function by corresponding to the age at 0.95 times $L_{inf}$, but can also be fixed, with the argument 'agemax'.

The fit of estimated growth parameters can also be explored visually (Fig. 5) and indicates high similarity with true growth curves and a good fit through the peaks of the LFQ data.

```{r Figure 6, echo = TRUE, fig.cap="Graphical fit of estimated and true growth curves plotted through the length frequency data. The growth curves with the true values are displayed in grey, while the yellow and orange curves represent the curves of the traditional ELEFAN method and ELEFAN with simulated annealing, respectively."}
# plot LFQ and growth curves
plot(lfqbin, Fname = "rcounts",date.axis = "modern")
lt <- lfqFitCurves(lfqbin, par = list(Linf=33.7, K=0.47, t_anchor=0.25), 
                   draw = TRUE, col = "blue", lty = 1, lwd=1.5)
lt <- lfqFitCurves(lfqbin, par = list(Linf=33.5, K=0.5, t_anchor=0.23), 
                   draw = TRUE, col = "goldenrod1", lty = 1, lwd=1.5)
lt <- lfqFitCurves(lfqbin, par = list(Linf=33.6, K=0.49, t_anchor=0.23), 
                   draw = TRUE, col = "darkgreen", lty = 1, lwd=1.5)
```

For further analysis, we use the outcomes of the simulated annealing approach by adding them to the Thumbprint Emperor data list.

```{r}
# assign estimates to the data list
synLFQ6 <- c(synLFQ6, res_SA$par)
```

###*Natural mortality*
The instantaneous natural mortality rate (M) is an influential parameter of stock assessment models and its estimation is challenging [@Kenchington2014; @Powers2014]. When no controlled experiments or tagging data is available the main approach for its estimation is to use empirical formulas. Overall, there are at least 30 different empirical formulas for the estimation of this parameter [@Kenchington2014] relying on correlations with life history parameters and/or environmental information. We apply the two most recent formulae, which are based upon a meta-analysis of 201 fish species [@Then2015]. These methods require estimates of VBGF growth parameters ($L_{inf}$ and $K$) and the maximum age (`tmax`) [@Then2015].

```{r}
# estimation of M
Ms <- M_empirical(Linf = 33.6, K_l = 0.49, tmax = res_RSA$agemax, 
                  method = c("Then_tmax","Then_growth"))
# assign estimates to the data list
synLFQ6$M <- mean(Ms)
synLFQ6$M_sd <- sd(Ms)
```


The result is with $0.8$ ± $0.04$ year$^{-1}$ (mean ± SE) identical to the true value of $0.8$ year$^{-1}$.

##*Fisheries aspects*
###*Exploitation level*
In order to estimate the level of exploitation, knowledge on fishing mortality (F) (usually derived by subtracting natural mortality from total mortality) and gear selectivity is imperative. The length-converted catch curve allows the estimation of the instantaneous total mortality rate (Z) of LFQ data and the derivation of a selection ogive. Here we skip an in-depth selectivity exploration, because more data would be required for this assessment^[For a comprehensive description of selectivity estimation refer to @Millar1997b.]. The following approach assumes a logistic curve ogive, typical of trawl-net selectivity, which may provide an appropriate first estimate in the case of LFQ data derived from a mixture of gears.
Total mortality rate is estimated with a sample of the catch representative for the whole year. The function `lfqModify` rearranges the catch matrix in the required format (catch vector per year) and allows to pool the largest length classes with only a few individuals into a plus group (here length class 29.5 cm). As with the Powell Wetherall plot, the `reg_int` argument is necessary to avoid the interactive plotting function (more information in `help(catchCurve)`). The argument `calc_ogive` allows the estimation of the selection ogive.

```{r Figure 7, fig.cap="\\label{fig:catchCurve} Catch curve with selected points for the regression analysis and in the second panel the selection ogive with age at first capture.", message = FALSE, warning=FALSE}
# modify the data list
synLFQ6 <- lfqModify(synLFQ6, plus_group = c(TRUE, 29.5))
# run catch curve
res_cc <- catchCurve(synLFQ6,reg_int = c(13,28), calc_ogive = TRUE)
# assign estimates to the data list
synLFQ6$Z <- res_cc$Z
synLFQ6$FM <- synLFQ6$Z - synLFQ6$M
```

The catch curve analysis returns a Z value of $2.17 ± 0.02 year^{-1}$. By subtracting M from Z, the fishing mortality rate is derived: $F = 2.17 - 0.8 = 1.37 year^{-1}$ which is close to the true value of $1.3 year^{-1}$. The exploitation rate is defined as $E = F/Z$ and in this example 0.63. The selectivity function of the catch curve estimated a length at first capture ($L_{50}$) of 10.6 cm which is close to the true parameter of 10 cm.

##*Stock size and status*
###*Stock size and composition*
Jones' length converted cohort analysis (CA; REFERENCE XXXXX) - a modification of Pope's virtual population analysis (VPA) for LFQ data - estimates the trend of the fishing mortality across length classes of the stock and allows an estimation of the stock size. Beside the growth and mortality parameters, CA also requires the parameters a and b of the allometric length-weight relationship^[Here the true parameters of a = 0.017 and b = 3.042 are used assuming that this was calculated from length-weight data.] and an estimate for the terminal fishing mortality (`terminal_F`), which was set here to the result of the catch curve minus natural mortality (1.37^[For a discussion on this parameter see @Hilborn1992]). We further correct for the two months of the year where no sampling took place assuming the catch is comparable to the other months (`catch_corFac` = (1 + 2/12)).

```{r Figure 8, fig.cap="\\label{fig:vpa} Results of Jones' cohort analysis (CA).", message=FALSE,warning=FALSE}
# assign length-weight parameters to the data list
synLFQ6$a <- 0.017
synLFQ6$b <- 3.042
# run CA
vpa_res <- VPA(param = synLFQ6, terminalF = synLFQ6$FM, 
               analysis_type = "CA", 
               plot=TRUE, catch_corFac = (1+2/12))
# stock size
sz <- sum(vpa_res$annualMeanNr, na.rm =TRUE) / 1e3
# stock biomass
sb <- sum(vpa_res$meanBiomassTon, na.rm = TRUE)
# assign F per length class to the data list
synLFQ6$FM <- vpa_res$FM_calc
```

The results show the logistic shaped fishing pattern across length classes (red line in Fig. 7), even though larger classes seem to be underrepresented in the catches. The size of the stock is according to this method around 69'000 individuals or 2'028 thousand tons. These values deviate from the true values of 79'000 individuals and 1'818 thousand tons by 14.5 % and 10.4 % for stock size in numbers and biomass, respectively. The respective under- and overestimation of the stock size and stock biomass might be due to uncertainity introduced by the plus group or the 2 unsampled months and the variablity in the data generation model.

###*Yield per recruit modelling*
Prediction models (or per-recruit models, e.g. Thompson and Bell model) allow to evaluate the status of a fish stock in relation to reference levels and to infer input control measures, such as restricting fishing effort or regulating gear types and mesh sizes. 
<!---
In addition to already estimated parameters these models require the length at recruitment '$L_r$', which can be set equal to the smallest length in the catch. By default the Beverton and Holt yield per recruit model
--->
By default the Thompson and Bell model assumes knife edge selection ($L_{25}$ = $L_{50}$ = $L_{75}$)^[Note that the length at capture has 2 abbreviations $L_{50}$ and $L_c$.]; however, the parameter `s_list` allows for changes of the selectivity assumptions. The parameter `FM_change` determines the range of F for which to estimate the yield and biomass trajectories. In the second application of this model, the impact of mesh size restrictions on yield is explored by changing $L_{c}$ (`Lc_change`) and F (`FM_change`, or exploitation rate, `E_change`) simultaneously. The resulting estimates are presented as an isopleth graph showing yield per recruit. By setting the argument `stock_size_1` to 1, all results are per recruit. If the number of recruits (recruitment to the fishery) are known, the exact yield and biomass can be estimated. The arguments `curr.E` and `curr.Lc` allow to derive and visualise yield and biomass (per recruit) values for current fishing patterns (Fig. 8).

```{r Figure 9,  fig.cap="\\label{fig:ypr} Thompson and Bell model for the Thumbprint Emperor data: (a) Curves of yield and biomass per recruit for the Thumbprint Emperor data with a Lc of 10.6. The black dot represents yield and biomass under current fishing pressure. The yellow and red dashed lines represent fishing mortality for maximum sustainable yield (Fmsy) and fishing mortality to fish the stock at 50% of the virgin biomass (F0.5). (b) exploration of impact of different exploitation rates and Lc values on the relative yield per recruit."}
# Thompson and Bell model with changes in F
TB1 <- predict_mod(synLFQ6, type = "ThompBell",
                   FM_change = seq(0,5,0.05),  stock_size_1 = 1,
                   curr.E = 0.63, plot = FALSE, hide.progressbar = TRUE)
# Thompson and Bell model with changes in F and Lc
TB2 <- predict_mod(synLFQ6, type = "ThompBell", 
                   FM_change = seq(0,5,0.1), Lc_change = seq(3,30,0.05), 
                   stock_size_1 = 1,
                   curr.E = 0.63, curr.Lc = res_cc$L50,
                   s_list = list(selecType = "trawl_ogive", 
                                 L50 = res_cc$L50, L75 = res_cc$L75),
                   plot = FALSE, hide.progressbar = TRUE)
# plot results 
par(mfrow = c(2,1), mar = c(4,5,2,4.5), oma = c(1,0,0,0))
plot(TB1, mark = TRUE)
mtext("(a)", side = 3, at = -1, line = 0.6)
plot(TB2, type = "Isopleth", xaxis1 = "E", mark = TRUE, contour = 6)
mtext("(b)", side = 3, at = -0.1, line = 0.6)
# Biological reference levels
brl <- TB1$df_Es
# Current yield and biomass levels
cl <- TB1$currents
```

The results indicate that the fishing mortality of this example ($F = 1.35$) is higher than the fishing mortality for MSY ($F_{MSY} = 0.9$), which confirms the indication of the slightly increased exploitation rate ($E = 0.63$). Figure 8a clearly shows that the yield could be increased when fishing mortality is reduced. The gear related analysis reveals that the current gear characteristics and exploitation rate produce a yield of above 25 g per recruit, which could be increased to above 30 g by increasing the mesh size (following vertical dashed line in Fig. 8b upwards).

#*References*

